{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp6-GjpouqxC"
      },
      "outputs": [],
      "source": [
        "#############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWtw0kBeMjTQ"
      },
      "outputs": [],
      "source": [
        "##################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "yZryLL0tyBJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the DeepFool attack function\n",
        "def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=50):\n",
        "    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "    net.eval()  # Set model to evaluation mode\n",
        "    f_image = net.forward(image).data.cpu().numpy().flatten()\n",
        "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
        "    I = I[0:num_classes]\n",
        "    label = I[0]\n",
        "    input_shape = image.cpu().detach().numpy().shape\n",
        "    pert_image = image.cpu().detach().numpy()\n",
        "    w = np.zeros(input_shape)\n",
        "    r_tot = np.zeros(input_shape)\n",
        "\n",
        "    loop_i = 0\n",
        "    while label == I[0] and loop_i < max_iter:\n",
        "\n",
        "        pert = np.inf\n",
        "        gradients = np.zeros(input_shape)\n",
        "\n",
        "        for k in range(1, num_classes):\n",
        "            x = np.copy(w)\n",
        "            w_norm = np.linalg.norm(w.flatten())\n",
        "            if w_norm == 0:\n",
        "                r_i = (overshoot / np.sqrt(np.prod(input_shape))) * np.sign(np.random.randn(*input_shape))\n",
        "            else:\n",
        "                r_i = (overshoot / w_norm) * w\n",
        "            pert_image = image + (1 + overshoot) * torch.from_numpy(r_i).float().to(device)\n",
        "            pert_image.requires_grad = True\n",
        "            net.zero_grad()\n",
        "            x = torch.from_numpy(x).float().to(device)\n",
        "            output = net.forward(pert_image)\n",
        "            loss = nn.CrossEntropyLoss()(output, torch.tensor([label]).to(device))\n",
        "            loss.backward()\n",
        "            grad = pert_image.grad.cpu().numpy()\n",
        "            gradients = gradients + grad\n",
        "\n",
        "            if k == 1:\n",
        "                w = np.copy(gradients)\n",
        "            else:\n",
        "                w = np.copy(gradients) - np.sum(gradients * w, axis=3, keepdims=True) * w / np.linalg.norm(w.flatten())\n",
        "\n",
        "            w_norm = np.linalg.norm(w.flatten())\n",
        "            if w_norm == 0:\n",
        "                r_i = (overshoot / np.sqrt(np.prod(input_shape))) * np.sign(np.random.randn(*input_shape))\n",
        "            else:\n",
        "                r_i = (overshoot / w_norm) * w\n",
        "\n",
        "            pert = np.linalg.norm(r_i)\n",
        "\n",
        "            if pert < 0.1:\n",
        "                r_tot = r_tot + r_i\n",
        "                break\n",
        "\n",
        "        loop_i += 1\n",
        "\n",
        "        pert_image = image + torch.from_numpy(r_tot).float().to(device)\n",
        "\n",
        "        f_pert = net.forward(pert_image).data.cpu().numpy().flatten()\n",
        "        if (np.array(f_pert)).flatten().argsort()[::-1][0] != label:\n",
        "            r_tot = np.zeros(input_shape)\n",
        "\n",
        "    return torch.from_numpy(r_tot).float().to(device)"
      ],
      "metadata": {
        "id": "iA5mvSWXyBMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJmtFxU4yBOW",
        "outputId": "edf420fa-772f-47f4-8795-cdd97b8bd166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EYlfG7cfyBQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the training function\n",
        "def train(model, optimizer, criterion, trainloader, device, num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Apply DeepFool attack to the inputs\n",
        "            perturbations = deepfool(inputs, model)\n",
        "            perturbed_inputs = inputs + perturbations\n",
        "\n",
        "            outputs = model(perturbed_inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / (i + 1)))\n"
      ],
      "metadata": {
        "id": "TQW7YjmbyBSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the neural network using federated learning\n",
        "num_clients = 10\n",
        "local_epochs = 10\n",
        "num_epochs = 50\n",
        "lr = 0.01"
      ],
      "metadata": {
        "id": "gRzPduLfyjRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the CIFAR-10 dataset into non-iid portions for each client\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_partitions = {}\n",
        "label_partitions = {}\n",
        "for i in range(num_clients):\n",
        "    data_partitions[i] = trainset.data[i::num_clients]\n",
        "    label_partitions[i] = trainset.targets[i::num_clients]\n",
        "\n",
        "clients = {}\n",
        "for i in range(num_clients):\n",
        "    clients[i] = {}\n",
        "    clients[i]['data'] = torch.from_numpy(data_partitions[i]).to(device)\n",
        "    clients[i]['targets'] = torch.tensor(label_partitions[i], dtype=torch.long).to(device)\n",
        "    clients[i]['model'] = Net().to(device)\n",
        "    clients[i]['optimizer'] = optim.SGD(clients[i]['model'].parameters(), lr=lr)\n",
        "    clients[i]['criterion'] = nn.CrossEntropyLoss()\n",
        "\n",
        "global_model = Net().to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Global epoch %d' % (epoch + 1))\n",
        "    global_model.train()\n",
        "\n",
        "    # Train local models\n",
        "    for i in range(num_clients):\n",
        "        print('Client %d training' % i)\n",
        "        train(clients[i]['model'], clients[i]['optimizer'], clients[i]['criterion'], \\\n",
        "              torch.utils.data.TensorDataset(clients[i]['data'], clients[i]['targets']), device, local_epochs)\n",
        "\n",
        "        # Update the global model with the local model weights\n",
        "        for global_param, local_param in zip(global_model.parameters(), clients[i]['model'].parameters()):\n",
        "            global_param.data += local_param.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "SKsioSWoMHaW",
        "outputId": "106d0848-7d3b-48b4-bd9e-7e1d50ec47b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global epoch 1\n",
            "Client 0 training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ff788ec7ae26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Client %d training'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         train(clients[i]['model'], clients[i]['optimizer'], clients[i]['criterion'], \\\n\u001b[0m\u001b[1;32m     29\u001b[0m               torch.utils.data.TensorDataset(clients[i]['data'], clients[i]['targets']), device, local_epochs)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-643d4e60e541>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, trainloader, device, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Apply DeepFool attack to the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mperturbations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mperturbed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mperturbations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-2387be5ffd0b>\u001b[0m in \u001b[0;36mdeepfool\u001b[0;34m(image, net, num_classes, overshoot, max_iter)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add batch dimension and move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mf_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-508b4144ae79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average the global model weights over all clients\n",
        "for global_param in global_model.parameters():\n",
        "    global_param.data /= num_clients"
      ],
      "metadata": {
        "id": "hrsciN2BMUej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the global model on the test set\n",
        "global_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = global_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy on the test set: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "kYdsGmnRMW2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s09KJJc4uaCi"
      },
      "outputs": [],
      "source": [
        "###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdQdlDBjuaso"
      },
      "outputs": [],
      "source": [
        "#################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7Ra4mz_ubT-"
      },
      "outputs": [],
      "source": [
        "##################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldD5JapYub-j"
      },
      "outputs": [],
      "source": [
        "#################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import copy\n",
        "from torchvision import models"
      ],
      "metadata": {
        "id": "F7-6ijbwDfaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set up the transforms\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqxNxgtDENKL",
        "outputId": "79a966b3-c566-4ea4-db6c-d8fd9e5196c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deepfool_attack(model, x, num_classes=10, max_iter=50, epsilon=0.02):\n",
        "    # Convert x to a tensor\n",
        "    x = x.clone().detach().requires_grad_(True).to(device)\n",
        "    # Get the output of the model\n",
        "    output = model(x.unsqueeze(0))\n",
        "    # Get the predicted label\n",
        "    label = torch.argmax(output, dim=1)\n",
        "    # Initialize the perturbation\n",
        "    perturbation = torch.zeros_like(x)\n",
        "    # Loop until the perturbation fools the model\n",
        "    for i in range(max_iter):\n",
        "        # Calculate the gradients of the output with respect to x\n",
        "        output[0, label].backward(retain_graph=True)\n",
        "        grads = x.grad.clone().detach()\n",
        "        # Calculate the perturbation\n",
        "        w = torch.zeros((num_classes, 1)).to(device)\n",
        "        f = torch.zeros((num_classes, 1)).to(device)\n",
        "        for j in range(num_classes):\n",
        "            if j == label:\n",
        "                continue\n",
        "            output[0, j].backward(retain_graph=True)\n",
        "            w[j] = x.grad.clone().detach().view(-1)\n",
        "            f[j] = output[0, j].clone().detach() - output[0, label].clone().detach()\n",
        "            x.grad.data.zero_()\n",
        "        f_prime = torch.abs(f)\n",
        "        index_sorted = torch.argsort(f_prime, dim=0, descending=True)\n",
        "        t = 0\n",
        "        sum_pert = torch.zeros_like(x)\n",
        "        while t < num_classes - 1 and torch.argmax(f_prime[index_sorted[t]]) == label:\n",
        "            j = index_sorted[t]\n",
        "            pert = (abs(f[j]) + epsilon) / torch.norm(w[j])\n",
        "            sum_pert += pert * w[j].view(x.shape)\n",
        "            t += 1\n",
        "        perturbation += sum_pert\n",
        "        perturbed_x = x + perturbation \n",
        "        # Check if the perturbed image fools the model\n",
        "        perturbed_output = model(perturbed_x.unsqueeze(0))\n",
        "        perturbed_label = torch.argmax(perturbed_output, dim=1)\n",
        "        if perturbed_label != label:\n",
        "            break\n",
        "        else:\n",
        "            perturbation *= 0.9\n",
        "    return perturbed_x.detach()\n"
      ],
      "metadata": {
        "id": "9HRJGUAvA1CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the CNN architecture\n",
        "# class CNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(CNN, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "#         self.relu1 = nn.ReLU()\n",
        "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "#         self.relu2 = nn.ReLU()\n",
        "#         self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "#         self.relu3 = nn.ReLU()\n",
        "#         self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.fc1 = nn.Linear(4*4*128, 256)\n",
        "#         self.relu4 = nn.ReLU()\n",
        "#         self.dropout1 = nn.Dropout(p=0.5)\n",
        "#         self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.relu1(out)\n",
        "#         out = self.maxpool1(out)\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.relu2(out)\n",
        "#         out = self.maxpool2(out)\n",
        "#         out = self.conv3(out)\n",
        "#         out = self.relu3(out)\n",
        "#         out = self.maxpool3(out)\n",
        "#         out = out.view(out.size(0), -1)\n",
        "#         out = self.fc1(out)\n",
        "#         out = self.relu4(out)\n",
        "#         out = self.dropout1(out)\n",
        "#         out = self.fc2(out)\n",
        "#         return out\n",
        "\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.fc = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# model = ResNet18().to(device)\n"
      ],
      "metadata": {
        "id": "YAn7dSSRA7va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "MnQZ47E9EeNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = transforms.Resize(224)(data)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Generate adversarial examples using the DeepFool attack for each image in the batch\n",
        "        perturbed_batch = []\n",
        "        for img_idx in range(data.shape[0]):\n",
        "            adv_example = deepfool_attack(model, data[img_idx])\n",
        "            perturbed_batch.append(adv_example.unsqueeze(0))\n",
        "        perturbed_batch = torch.cat(perturbed_batch, dim=0)\n",
        "\n",
        "        # Pass the perturbed batch through the model\n",
        "        output = model(perturbed_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    train_acc = 100. * correct / total\n",
        "    train_loss /= len(train_loader)\n",
        "    print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        train_loss, correct, total, train_acc))\n",
        "    return train_loss, train_acc\n"
      ],
      "metadata": {
        "id": "XT-vWcwIBJnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "    test_acc = 100. * correct / total\n",
        "    test_loss /= len(test_loader)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, total, test_acc))\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "tyAUuu0OBKdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Federated Learning function\n",
        "def federated_learning(model, train_loaders, test_loader, num_rounds=10, lr=0.1, momentum=0.9, epsilon=0.03):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    for round_ in range(num_rounds):\n",
        "        # Clone the model for each client\n",
        "        client_models = [copy.deepcopy(model) for _ in range(len(train_loaders))]\n",
        "        # Train each client model\n",
        "        train_losses = []\n",
        "        train_accs = []\n",
        "        for i, (train_loader, client_model) in enumerate(zip(train_loaders, client_models)):\n",
        "            print(f\"Round: {round_}, Client: {i+1}\")\n",
        "            client_model.train()\n",
        "            optimizer = optim.SGD(client_model.parameters(), lr=lr, momentum=momentum)\n",
        "            train_loss, train_acc = train(client_model, train_loader, optimizer, criterion, round_)\n",
        "            train_losses.append(train_loss)\n",
        "            train_accs.append(train_acc)\n",
        "        # Aggregate the client models using Federated Averaging\n",
        "        for param in model.parameters():\n",
        "            param.data = torch.zeros_like(param.data)\n",
        "        for client_model in client_models:\n",
        "            for param, client_param in zip(model.parameters(), client_model.parameters()):\n",
        "                param.data += client_param.data / len(client_models)\n",
        "        \n",
        "        # Evaluate the aggregated model\n",
        "        test_loss_round, test_acc_round = test(model, test_loader, criterion)\n",
        "        test_loss.append(test_loss_round)\n",
        "        test_acc.append(test_acc_round)\n",
        "\n",
        "    return train_losses, train_accs, test_loss, test_acc\n"
      ],
      "metadata": {
        "id": "JTGrJJsCBRjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the data and model\n",
        "num_clients = 10\n",
        "epsilon=0.03\n",
        "momentum = 0.9\n",
        "lr=0.01\n",
        "train_loaders = [torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True) for _ in range(num_clients)]\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False) \n",
        "model = ResNet18().to(device)\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accs, test_loss, test_acc = federated_learning(model, train_loaders, test_loader, lr=lr, momentum=momentum, epsilon=epsilon)\n",
        "\n",
        "# Print the results\n",
        "print('Train Losses:', train_losses)\n",
        "print('Train Accuracies:', train_accs)\n",
        "print('Test Losses:', test_loss)\n",
        "print('Test Accuracies:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "IpZFBl-NBYhX",
        "outputId": "3101518c-830f-4227-99f4-2e7cafd472e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round: 0, Client: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-4c9464e3e828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-08277c251410>\u001b[0m in \u001b[0;36mfederated_learning\u001b[0;34m(model, train_loaders, test_loader, num_rounds, lr, momentum, epsilon)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mclient_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-990e6714a525>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mperturbed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0madv_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepfool_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mperturbed_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mperturbed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-ff33b38e7de5>\u001b[0m in \u001b[0;36mdeepfool_attack\u001b[0;34m(model, x, num_classes, max_iter, epsilon)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (150528) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [150528]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################################################"
      ],
      "metadata": {
        "id": "3q9fCKCkn8Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################################################"
      ],
      "metadata": {
        "id": "3O2c3c36V5RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################################################"
      ],
      "metadata": {
        "id": "J-9mpqziV8Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################################################"
      ],
      "metadata": {
        "id": "pvAMNssOV9Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################################################"
      ],
      "metadata": {
        "id": "fkPDM_eSV9Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################################################################################################"
      ],
      "metadata": {
        "id": "NJC_cGunV9c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "aab26bdbe3ab4e5a934d14a5ed636dcb",
            "3f2e017c06854873b4dbee197956aeb8",
            "d5d411bf9f804a55a20ad05daab27bfa",
            "c3d474abfb76453e98f1095e879b9611",
            "cf5a02b81fc24552b08bf8f0c29c2676",
            "242086c32db34b47ac9586e454443e3c",
            "cd8bff205bdb44b58a201c3264a09f21",
            "3eda4fa4e8294aa183d48d766d0e1194",
            "3162150e7b9b4eec9b6c8f760f164383",
            "e8d20f4feefe4117884c6547c6f16ea0",
            "66aede61240f4717ba36213b2b73f400"
          ]
        },
        "id": "f8i0TRP5V9nu",
        "outputId": "53818362-41d8-43a5-c253-cc44fdef9796"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aab26bdbe3ab4e5a934d14a5ed636dcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Define deepfool attack function\n",
        "# def deepfool_attack(image, model, num_classes=10, overshoot=0.02, max_iter=50):\n",
        "#     \"\"\"\n",
        "#     Deepfool attack implementation for CIFAR-10 images.\n",
        "#     \"\"\"\n",
        "#     # Convert image to tensor and send to device\n",
        "#     image = image.to(device)\n",
        "#     image.requires_grad = True\n",
        "    \n",
        "#     # Get predicted label for image\n",
        "#     output = model(image)\n",
        "#     init_pred = output.max(1, keepdim=True)[1].item()\n",
        "    \n",
        "#     # Initialize perturbation\n",
        "#     perturbation = torch.zeros_like(image).to(device)\n",
        "#     perturbed_image = torch.zeros_like(image).to(device)\n",
        "    \n",
        "#     # Initialize counter and loop until the image is misclassified\n",
        "#     i = 0\n",
        "#     while init_pred == output.max(1, keepdim=True)[1].item() and i < max_iter:\n",
        "#         # Calculate gradients and get predicted label\n",
        "#         output.backward()\n",
        "#         grad = image.grad.data\n",
        "#         pred_label = output.max(1, keepdim=True)[1].item()\n",
        "        \n",
        "#         # Initialize min and min_index\n",
        "#         min_norm = float('inf')\n",
        "#         min_index = None\n",
        "        \n",
        "#         # Loop through all classes\n",
        "#         for k in range(num_classes):\n",
        "#             # Skip if class is equal to predicted class\n",
        "#             if k == pred_label:\n",
        "#                 continue\n",
        "            \n",
        "#             # Calculate perturbation for class k\n",
        "#             w_k = grad[k, :, :, :].clone()\n",
        "#             w = grad[pred_label, :, :, :].clone()\n",
        "#             f_k = output[0, k].item()\n",
        "#             f = output[0, pred_label].item()\n",
        "#             pert_k = abs(f_k - f) / torch.norm(w_k - w)\n",
        "            \n",
        "#             # Update min_norm and min_index if perturbation for class k is smaller\n",
        "#             if pert_k < min_norm:\n",
        "#                 min_norm = pert_k\n",
        "#                 min_index = k\n",
        "        \n",
        "#         # Update perturbation and perturbed_image\n",
        "#         r = min_norm * (w - w_k)\n",
        "#         perturbation += r\n",
        "#         perturbed_image = image + (1 + overshoot) * perturbation\n",
        "        \n",
        "#         # Clamp the perturbed image to valid range\n",
        "#         perturbed_image = torch.clamp(perturbed_image, 0, 1).detach()\n",
        "        \n",
        "#         # Reset gradients and increment counter\n",
        "#         model.zero_grad()\n",
        "#         output = model(perturbed_image)\n",
        "#         i += 1\n",
        "        \n",
        "#     return perturbed_image.detach(), init_pred, output.max(1, keepdim=True)[1].item()\n",
        "\n",
        "\n",
        "\n",
        "def deepfool_attack(image, model, num_classes=10, overshoot=0.02, max_iter=50):\n",
        "    \"\"\"\n",
        "    Deepfool attack implementation for CIFAR-10 images.\n",
        "    \"\"\"\n",
        "    # Convert image to tensor and send to device\n",
        "    image = image.to(device)\n",
        "    image.requires_grad = True\n",
        "    \n",
        "    # Get predicted label for image\n",
        "    with torch.enable_grad():\n",
        "        output = model(image)\n",
        "    # init_pred = output.max(1, keepdim=True)[1].item()\n",
        "    \n",
        "    # Check if output tensor is empty\n",
        "    if output.numel() == 0:\n",
        "        return None, None, None\n",
        "    output_sum = output.sum()\n",
        "    init_pred = output.max(1, keepdim=True)[1].item()\n",
        "    # Initialize perturbation\n",
        "    perturbation = torch.zeros_like(image).to(device)\n",
        "    perturbed_image = torch.zeros_like(image).to(device)\n",
        "    \n",
        "    # Initialize counter and loop until the image is misclassified\n",
        "    i = 0\n",
        "    while init_pred == output.max(1, keepdim=True)[1].item() and i < max_iter and output.numel() > 0:\n",
        "\n",
        "        # Calculate gradients and get predicted label\n",
        "        image.grad = torch.zeros_like(image)\n",
        "        grad = image.grad.data\n",
        "        \n",
        "        output.backward(torch.ones_like(output), retain_graph=True)\n",
        "        grad = image.grad.clone().detach()\n",
        "\n",
        "        pred_label = output.max(1, keepdim=True)[1].item()\n",
        "        \n",
        "        # Initialize min and min_index\n",
        "        min_norm = float('inf')\n",
        "        min_index = None\n",
        "        \n",
        "        # Loop through all classes\n",
        "        for k in range(num_classes):\n",
        "            # Skip if class is equal to predicted class\n",
        "            if k == pred_label:\n",
        "                continue\n",
        "            \n",
        "            # Calculate perturbation for class k\n",
        "            w_k = grad.clone()\n",
        "            w_k[0, pred_label] = 0\n",
        "            w = grad.clone()\n",
        "            w[0, k] = 0\n",
        "\n",
        "\n",
        "            f_k = output[0, k].item()\n",
        "            f = output[0, pred_label].item()\n",
        "            pert_k = abs(f_k - f) / torch.norm(w_k - w)\n",
        "            \n",
        "            # Update min_norm and min_index if perturbation for class k is smaller\n",
        "            if pert_k < min_norm:\n",
        "                min_norm = pert_k\n",
        "                min_index = k\n",
        "        \n",
        "        # Update perturbation and perturbed_image\n",
        "        r = min_norm * (w - w_k)\n",
        "        perturbation += r\n",
        "        perturbed_image = image + (1 + overshoot) * perturbation\n",
        "\n",
        "        # Clamp the perturbed image to valid range\n",
        "        perturbed_image = torch.clamp(perturbed_image, 0, 1).detach()\n",
        "\n",
        "\n",
        "        \n",
        "        # # Update perturbation and perturbed_image\n",
        "        # r = min_norm * (w - w_k)\n",
        "        # perturbation += r\n",
        "        # perturbed_image = image + (1 + overshoot) * perturbation\n",
        "        \n",
        "        # # Clamp the perturbed image to valid range\n",
        "       \n",
        "\n",
        "\n",
        "        \n",
        "        # # Update perturbation and perturbed_image\n",
        "        # r = min_norm * (w - w_k)\n",
        "        # perturbation += r\n",
        "        # perturbed_image = image + (1 + overshoot) * perturbation\n",
        "        \n",
        "        # # Clamp the perturbed image to valid range\n",
        "        # perturbed_image = torch.clamp(perturbed_image, 0, 1).detach()\n",
        "        \n",
        "        # Reset gradients and increment counter\n",
        "        model.zero_grad()\n",
        "        with torch.enable_grad():\n",
        "            output = model(perturbed_image)\n",
        "            output_sum = output.sum()\n",
        "        i += 1\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "    return perturbed_image.detach(), init_pred, output.max(1, keepdim=True)[1].item()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AA4LWcFaWC-_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 128, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(-1, 4 * 4 * 128)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize model and optimizer\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "IImAQ7QZWJJj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_interval=10\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if data.shape[0] == 1:\n",
        "            continue\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GwDoWGVlWN3J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def test(model, test_loader):\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     with torch.no_grad():\n",
        "#         for data, target in test_loader:\n",
        "#             data, target = data.to(device), target.to(device)\n",
        "#             output = model(data)\n",
        "#             test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "#     test_loss /= len(test_loader.dataset)\n",
        "\n",
        "#     accuracy = 100. * correct / len(test_loader.dataset)\n",
        "#     print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)\")\n",
        "#     return accuracy\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            # Apply deepfool attack on first image in batch\n",
        "            perturbed_image, init_pred, adv_pred = deepfool_attack(data[0], model)\n",
        "\n",
        "            # Get predicted label for perturbed image\n",
        "            output = model(perturbed_image.unsqueeze(0))\n",
        "            adv_pred = output.max(1, keepdim=True)[1].item()\n",
        "\n",
        "            # Calculate loss and accuracy\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({accuracy:.2f}%), Adv Accuracy: {len(test_loader.dataset) - correct}/{len(test_loader.dataset)} '\n",
        "          f'({100 - accuracy:.2f}%)')\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "caSDNgcAWW-o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Federated Learning setup\n",
        "# Initialize Federated Learning setup\n",
        "# Initialize Federated Learning setup\n",
        "num_clients = 10\n",
        "train_loaders = []\n",
        "test_loaders = []\n",
        "\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_subsplits = torch.utils.data.random_split(trainset, [int(len(train_dataset)/num_clients) for _ in range(num_clients)])\n",
        "test_subsplits = torch.utils.data.random_split(testset, [int(len(test_dataset)/num_clients) for _ in range(num_clients)])\n",
        "\n",
        "for i in range(num_clients):\n",
        "    train_loader = torch.utils.data.DataLoader(train_subsplits[i], batch_size=128, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_subsplits[i], batch_size=128, shuffle=False)\n",
        "    \n",
        "    train_loaders.append(train_loader)\n",
        "    test_loaders.append(test_loader)\n",
        "\n",
        "\n",
        "\n",
        "# Define Federated Learning function\n",
        "def federated_learning(model, train_loaders, test_loaders, optimizer, num_epochs):\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
        "        for i in range(num_clients):\n",
        "            print(f\"Client {i + 1}\")\n",
        "            model = train(model, train_loaders[i], optimizer, epoch + 1)\n",
        "        test_accs = []\n",
        "        for i in range(num_clients):\n",
        "            test_acc = test(model, test_loaders[i])\n",
        "            test_accs.append(test_acc)\n",
        "        print(f\"Test Accuracy: {sum(test_accs) / len(test_accs)}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Train the model using Federated Learning\n",
        "model = federated_learning(model, train_loaders, test_loaders, optimizer, num_epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vaahGypVWaCo",
        "outputId": "8e758534-3659-47eb-dbf7-a034db42fd0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Client 1\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.302668\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.290805\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.262135\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.184063\n",
            "Client 2\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.237004\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.215704\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.183702\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.154138\n",
            "Client 3\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.184165\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.171565\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.249456\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.186972\n",
            "Client 4\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.135293\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.180833\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.171788\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.162971\n",
            "Client 5\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.152950\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.147805\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.189826\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.158328\n",
            "Client 6\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.125875\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.231234\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.181404\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.201127\n",
            "Client 7\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.130881\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.193731\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.080462\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.136255\n",
            "Client 8\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.162266\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.189239\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.055439\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.144355\n",
            "Client 9\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.057866\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.058972\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.080205\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.092188\n",
            "Client 10\n",
            "Train Epoch: 1 [0/5000 (0%)]\tLoss: 2.076941\n",
            "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 2.092688\n",
            "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 2.020108\n",
            "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 2.029011\n",
            "Test set: Average loss: 2.0482, Accuracy: 418/1000 (41.80%), Adv Accuracy: 582/1000 (58.20%)\n",
            "Test set: Average loss: 2.0710, Accuracy: 386/1000 (38.60%), Adv Accuracy: 614/1000 (61.40%)\n",
            "Test set: Average loss: 2.0434, Accuracy: 422/1000 (42.20%), Adv Accuracy: 578/1000 (57.80%)\n",
            "Test set: Average loss: 2.0736, Accuracy: 387/1000 (38.70%), Adv Accuracy: 613/1000 (61.30%)\n",
            "Test set: Average loss: 2.0507, Accuracy: 397/1000 (39.70%), Adv Accuracy: 603/1000 (60.30%)\n",
            "Test set: Average loss: 2.0688, Accuracy: 393/1000 (39.30%), Adv Accuracy: 607/1000 (60.70%)\n",
            "Test set: Average loss: 2.0573, Accuracy: 404/1000 (40.40%), Adv Accuracy: 596/1000 (59.60%)\n",
            "Test set: Average loss: 2.0651, Accuracy: 386/1000 (38.60%), Adv Accuracy: 614/1000 (61.40%)\n",
            "Test set: Average loss: 2.0670, Accuracy: 394/1000 (39.40%), Adv Accuracy: 606/1000 (60.60%)\n",
            "Test set: Average loss: 2.0526, Accuracy: 412/1000 (41.20%), Adv Accuracy: 588/1000 (58.80%)\n",
            "Test Accuracy: 39.989999999999995\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Client 1\n",
            "Train Epoch: 2 [0/5000 (0%)]\tLoss: 2.062112\n",
            "Train Epoch: 2 [1280/5000 (25%)]\tLoss: 2.062027\n",
            "Train Epoch: 2 [2560/5000 (50%)]\tLoss: 2.091935\n",
            "Train Epoch: 2 [3840/5000 (75%)]\tLoss: 2.124041\n",
            "Client 2\n",
            "Train Epoch: 2 [0/5000 (0%)]\tLoss: 2.052692\n",
            "Train Epoch: 2 [1280/5000 (25%)]\tLoss: 2.087147\n",
            "Train Epoch: 2 [2560/5000 (50%)]\tLoss: 2.089869\n",
            "Train Epoch: 2 [3840/5000 (75%)]\tLoss: 1.999455\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5801894b8239>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Train the model using Federated Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-5801894b8239>\u001b[0m in \u001b[0;36mfederated_learning\u001b[0;34m(model, train_loaders, test_loaders, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Client {i + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtest_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a311c49a8c99>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ssETEYzoMPlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aab26bdbe3ab4e5a934d14a5ed636dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f2e017c06854873b4dbee197956aeb8",
              "IPY_MODEL_d5d411bf9f804a55a20ad05daab27bfa",
              "IPY_MODEL_c3d474abfb76453e98f1095e879b9611"
            ],
            "layout": "IPY_MODEL_cf5a02b81fc24552b08bf8f0c29c2676"
          }
        },
        "3f2e017c06854873b4dbee197956aeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242086c32db34b47ac9586e454443e3c",
            "placeholder": "​",
            "style": "IPY_MODEL_cd8bff205bdb44b58a201c3264a09f21",
            "value": "100%"
          }
        },
        "d5d411bf9f804a55a20ad05daab27bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eda4fa4e8294aa183d48d766d0e1194",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3162150e7b9b4eec9b6c8f760f164383",
            "value": 170498071
          }
        },
        "c3d474abfb76453e98f1095e879b9611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d20f4feefe4117884c6547c6f16ea0",
            "placeholder": "​",
            "style": "IPY_MODEL_66aede61240f4717ba36213b2b73f400",
            "value": " 170498071/170498071 [00:05&lt;00:00, 32806350.71it/s]"
          }
        },
        "cf5a02b81fc24552b08bf8f0c29c2676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "242086c32db34b47ac9586e454443e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd8bff205bdb44b58a201c3264a09f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eda4fa4e8294aa183d48d766d0e1194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3162150e7b9b4eec9b6c8f760f164383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8d20f4feefe4117884c6547c6f16ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66aede61240f4717ba36213b2b73f400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}